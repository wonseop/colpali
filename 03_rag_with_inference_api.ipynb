{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: RAG with ColPali using Inference API (Amazon Bedrock)\n",
    "\n",
    "**Important Notice**: This notebook provides a guide to implement Retrieval-Augmented Generation (RAG) with ColPali using Elastic's Inference API integrated with Amazon Bedrock. The focus is on creating an Inference Endpoint for the Completion Task and performing natural language search and response generation on the RVL-CDIP dataset. This approach directly calls the Inference API using a Python client, bypassing the need for MCP Server setup.\n",
    "\n",
    "Follow the step-by-step guide below to configure the Inference Endpoint with Amazon Bedrock (using Claude 3.5 Sonnet), connect to Elastic Cloud, and perform a natural language search demo. This demo showcases the RAG approach, where Elasticsearch retrieves relevant documents using KNN+Rescore search (Retrieval) and the LLM in Amazon Bedrock generates responses based on the search results (Generation). Additionally, a Streamlit app is provided to create a visual demo.\n",
    "\n",
    "**Objective**: Set up an Inference Endpoint with Amazon Bedrock, connect it to Elastic Cloud, and implement a natural language search demo for the RVL-CDIP dataset in the ColPali project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[EN]** Load environment variables from `elastic.env` and `aws.env` to retrieve connection details for Elastic Cloud and Amazon Bedrock. If `aws.env` does not exist, create it with necessary credentials.<br>\n",
    "**[KR]** `elastic.env`와 `aws.env` 파일에서 환경 변수를 로드하여 Elastic Cloud와 Amazon Bedrock 연결 정보를 가져옵니다. `aws.env` 파일이 없으면 필요한 자격 증명으로 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, set_key\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from elastic.env and aws.env\n",
    "elastic_dotenv_path = 'elastic.env'\n",
    "aws_dotenv_path = 'aws.env'\n",
    "load_dotenv(dotenv_path=elastic_dotenv_path)\n",
    "load_dotenv(dotenv_path=aws_dotenv_path, override=True)\n",
    "\n",
    "# Retrieve Elastic Cloud connection details\n",
    "ELASTIC_HOST = os.getenv(\"ELASTIC_HOST\", os.getenv(\"ES_URL\", \"\"))\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTIC_API_KEY\", os.getenv(\"ES_API_KEY\", \"\"))\n",
    "\n",
    "if not ELASTIC_HOST or not ELASTIC_API_KEY:\n",
    "    raise ValueError(f\"Please create an '{elastic_dotenv_path}' file and set ELASTIC_HOST and ELASTIC_API_KEY variables.\")\n",
    "\n",
    "# Check if aws.env exists, if not create it with default placeholders\n",
    "aws_env_file = Path(aws_dotenv_path)\n",
    "if not aws_env_file.exists():\n",
    "    aws_env_file.touch(mode=0o600, exist_ok=False)\n",
    "    set_key(dotenv_path=aws_dotenv_path, key_to_set=\"AWS_ACCESS_KEY\", value_to_set=\"<your-aws-access-key>\")\n",
    "    set_key(dotenv_path=aws_dotenv_path, key_to_set=\"AWS_SECRET_KEY\", value_to_set=\"<your-aws-secret-key>\")\n",
    "    set_key(dotenv_path=aws_dotenv_path, key_to_set=\"AWS_REGION\", value_to_set=\"ap-northeast-2\")\n",
    "    print(f\"Created '{aws_dotenv_path}' with placeholder values. Please update it with your actual AWS credentials.\")\n",
    "else:\n",
    "    print(f\"'{aws_dotenv_path}' already exists. Loading values from it.\")\n",
    "\n",
    "# Retrieve Amazon Bedrock credentials and region\n",
    "AWS_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY\", \"\")\n",
    "AWS_SECRET_KEY = os.getenv(\"AWS_SECRET_KEY\", \"\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"ap-northeast-2\")\n",
    "\n",
    "if not AWS_ACCESS_KEY or not AWS_SECRET_KEY or AWS_ACCESS_KEY == \"<your-aws-access-key>\" or AWS_SECRET_KEY == \"<your-aws-secret-key>\":\n",
    "    raise ValueError(f\"Please update '{aws_dotenv_path}' with valid AWS_ACCESS_KEY and AWS_SECRET_KEY values.\")\n",
    "\n",
    "print(f\"Elastic Host loaded: {ELASTIC_HOST[:20]}... (partially hidden for security)\")\n",
    "print(f\"Elastic API Key loaded: {ELASTIC_API_KEY[:5]}... (partially hidden for security)\")\n",
    "print(f\"AWS Access Key loaded: {AWS_ACCESS_KEY[:5]}... (partially hidden for security)\")\n",
    "print(f\"AWS Secret Key loaded: {AWS_SECRET_KEY[:5]}... (partially hidden for security)\")\n",
    "print(f\"AWS Region loaded: {AWS_REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[EN]** Connect to Elastic Cloud using the loaded credentials to interact with Elasticsearch.<br>\n",
    "**[KR]** 로드된 자격 증명을 사용하여 Elastic Cloud에 연결하여 Elasticsearch와 상호작용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Connect to Elastic Cloud\n",
    "if \":\" in ELASTIC_HOST and not ELASTIC_HOST.startswith(\"http\"):\n",
    "    es = Elasticsearch(cloud_id=ELASTIC_HOST, api_key=ELASTIC_API_KEY)\n",
    "else:\n",
    "    es = Elasticsearch(hosts=[ELASTIC_HOST], api_key=ELASTIC_API_KEY)\n",
    "\n",
    "print(f\"Connected to Elasticsearch version: {es.info()['version']['number']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[EN]** Create an Inference Endpoint for Completion Task using Amazon Bedrock with Claude 3.5 Sonnet model.<br>\n",
    "**[KR]** Claude 3.5 Sonnet 모델을 사용한 Amazon Bedrock으로 Completion Task를 위한 Inference Endpoint를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create Inference Endpoint for Completion Task\n",
    "inference_id = \"amazon_bedrock_completion\"\n",
    "task_type = \"completion\"\n",
    "service = \"amazonbedrock\"\n",
    "provider = \"anthropic\"\n",
    "model = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "\n",
    "try:\n",
    "    response = es.inference.put(\n",
    "        task_type=task_type,\n",
    "        inference_id=inference_id,\n",
    "        inference_config={\n",
    "            \"service\": service,\n",
    "            \"service_settings\": {\n",
    "                \"access_key\": AWS_ACCESS_KEY,\n",
    "                \"secret_key\": AWS_SECRET_KEY,\n",
    "                \"region\": AWS_REGION,\n",
    "                \"provider\": provider,\n",
    "                \"model\": model\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(f\"Inference Endpoint created: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Inference Endpoint: {e}\")\n",
    "    print(\"Ensure your Elasticsearch version supports Amazon Bedrock integration (8.12.0 or higher).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[EN]** Perform a natural language search on RVL-CDIP dataset using KNN+Rescore and generate a response using the Inference API with Amazon Bedrock.<br>\n",
    "**[KR]** RVL-CDIP 데이터셋에 대해 KNN+Rescore를 사용하여 자연어 검색을 수행하고 Amazon Bedrock과 함께 Inference API를 사용하여 응답을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Perform RAG with Natural Language Search (KNN+Rescore) and Response Generation\n",
    "index_name = \"colqwen-rvlcdip-demo-part2-original\"\n",
    "query_text = \"Show me invoices with handwritten notes from the RVL-CDIP dataset.\"\n",
    "\n",
    "try:\n",
    "    # Search for relevant documents in RVL-CDIP dataset using KNN+Rescore\n",
    "    search_body = {\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        \"content\": query_text\n",
    "                    }\n",
    "                },\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                    \"params\": {\n",
    "                        \"query_vector\": [0.1, 0.2, 0.3]  # Placeholder vector, replace with actual query embedding if available\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"rescore\": {\n",
    "            \"window_size\": 10,\n",
    "            \"query\": {\n",
    "                \"rescore_query\": {\n",
    "                    \"knn\": {\n",
    "                        \"field\": \"embedding\",\n",
    "                        \"query_vector\": [0.1, 0.2, 0.3],  # Placeholder vector, replace with actual query embedding if available\n",
    "                        \"k\": 10,\n",
    "                        \"num_candidates\": 100\n",
    "                    }\n",
    "                },\n",
    "                \"query_weight\": 0.5,\n",
    "                \"rescore_query_weight\": 0.5\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "    search_response = es.search(index=index_name, body=search_body)\n",
    "    retrieved_docs = [hit[\"_source\"].get(\"content\", \"\") for hit in search_response[\"hits\"][\"hits\"]]\n",
    "    context = \"\\n\".join(retrieved_docs) if retrieved_docs else \"No relevant documents found.\"\n",
    "    \n",
    "    print(f\"Retrieved {len(retrieved_docs)} documents from {index_name} using KNN+Rescore.\")\n",
    "    print(f\"Context for LLM: {context[:200]}... (partially shown for brevity)\")\n",
    "    \n",
    "    # Call Inference API for Completion Task with Amazon Bedrock\n",
    "    inference_body = {\n",
    "        \"input\": f\"User Query: {query_text}\\nContext: {context}\\nAnswer based on the context.\"\n",
    "    }\n",
    "    inference_response = es.inference.completion(inference_id=\"amazon_bedrock_completion\", body=inference_body)\n",
    "    result = inference_response.get(\"completion\", [{}])[0].get(\"result\", \"No response generated.\")\n",
    "    \n",
    "    print(f\"LLM Response from Amazon Bedrock (Claude 3.5 Sonnet):\\n{result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during search or inference: {e}\")\n",
    "    print(\"Ensure the Inference Endpoint 'amazon_bedrock_completion' is created and active.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[EN]** Create a Streamlit app to provide a visual demo for natural language search and response generation using Inference API.<br>\n",
    "**[KR]** Inference API를 사용하여 자연어 검색 및 응답 생성을 위한 시각적 데모를 제공하는 Streamlit 앱을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a Streamlit App for Visual Demo\n",
    "streamlit_app_code = '''\n",
    "import streamlit as st\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('elastic.env')\n",
    "load_dotenv('aws.env', override=True)\n",
    "\n",
    "# Retrieve Elastic Cloud connection details\n",
    "ELASTIC_HOST = os.getenv(\"ELASTIC_HOST\", os.getenv(\"ES_URL\", \"\"))\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTIC_API_KEY\", os.getenv(\"ES_API_KEY\", \"\"))\n",
    "\n",
    "if not ELASTIC_HOST or not ELASTIC_API_KEY:\n",
    "    st.error(\"Elastic Cloud credentials not found. Please create 'elastic.env' with ELASTIC_HOST and ELASTIC_API_KEY.\")\n",
    "    st.stop()\n",
    "\n",
    "# Connect to Elastic Cloud\n",
    "if \":\" in ELASTIC_HOST and not ELASTIC_HOST.startswith(\"http\"):\n",
    "    es = Elasticsearch(cloud_id=ELASTIC_HOST, api_key=ELASTIC_API_KEY)\n",
    "else:\n",
    "    es = Elasticsearch(hosts=[ELASTIC_HOST], api_key=ELASTIC_API_KEY)\n",
    "\n",
    "if not es.ping():\n",
    "    st.error(\"Failed to connect to Elastic Cloud. Please check your credentials.\")\n",
    "    st.stop()\n",
    "\n",
    "st.title(\"ColPali RAG Demo with Inference API (Amazon Bedrock)\")\n",
    "st.write(\"Enter a natural language query to search the RVL-CDIP dataset and generate a response using Amazon Bedrock.\")\n",
    "\n",
    "query_text = st.text_input(\"Enter your search query:\", \"Show me invoices with handwritten notes from the RVL-CDIP dataset.\")\n",
    "index_name = \"colqwen-rvlcdip-demo-part2-original\"\n",
    "\n",
    "if st.button(\"Search and Generate Response\"):\n",
    "    try:\n",
    "        # Search for relevant documents in RVL-CDIP dataset using KNN+Rescore\n",
    "        search_body = {\n",
    "            \"query\": {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\n",
    "                        \"match\": {\n",
    "                            \"content\": query_text\n",
    "                        }\n",
    "                    },\n",
    "                    \"script\": {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                        \"params\": {\n",
    "                            \"query_vector\": [0.1, 0.2, 0.3]  # Placeholder vector, replace with actual query embedding if available\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"rescore\": {\n",
    "                \"window_size\": 10,\n",
    "                \"query\": {\n",
    "                    \"rescore_query\": {\n",
    "                        \"knn\": {\n",
    "                            \"field\": \"embedding\",\n",
    "                            \"query_vector\": [0.1, 0.2, 0.3],  # Placeholder vector, replace with actual query embedding if available\n",
    "                            \"k\": 10,\n",
    "                            \"num_candidates\": 100\n",
    "                        }\n",
    "                    },\n",
    "                    \"query_weight\": 0.5,\n",
    "                    \"rescore_query_weight\": 0.5\n",
    "                }\n",
    "            },\n",
    "            \"size\": 5\n",
    "        }\n",
    "        search_response = es.search(index=index_name, body=search_body)\n",
    "        retrieved_docs = [hit[\"_source\"].get(\"content\", \"\") for hit in search_response[\"hits\"][\"hits\"]]\n",
    "        context = \"\\n\".join(retrieved_docs) if retrieved_docs else \"No relevant documents found.\"\n",
    "        \n",
    "        st.write(f\"Retrieved {len(retrieved_docs)} documents from {index_name} using KNN+Rescore.\")\n",
    "        st.write(\"Context for LLM (partially shown for brevity):\")\n",
    "        st.text(context[:500] + \"...\" if len(context) > 500 else context)\n",
    "        \n",
    "        # Call Inference API for Completion Task with Amazon Bedrock\n",
    "        inference_body = {\n",
    "            \"input\": f\"User Query: {query_text}\\nContext: {context}\\nAnswer based on the context.\"\n",
    "        }\n",
    "        inference_response = es.inference.completion(inference_id=\"amazon_bedrock_completion\", body=inference_body)\n",
    "        result = inference_response.get(\"completion\", [{}])[0].get(\"result\", \"No response generated.\")\n",
    "        \n",
    "        st.write(\"LLM Response from Amazon Bedrock (Claude 3.5 Sonnet):\")\n",
    "        st.text(result)\n",
    "    except Exception as e:\n",
    "        st.write(f\"Error during search or inference: {e}\")\n",
    "        st.write(\"Ensure the Inference Endpoint 'amazon_bedrock_completion' is created and active.\")\n",
    "'''\n",
    "\n",
    "# Write the Streamlit app code to a file\n",
    "with open(\"colpali_rag_demo.py\", \"w\") as f:\n",
    "    f.write(streamlit_app_code)\n",
    "\n",
    "print(\"Streamlit app code saved as 'colpali_rag_demo.py'.\")\n",
    "print(\"To run the app, execute the following command in your terminal:\")\n",
    "print(\"  streamlit run colpali_rag_demo.py\")\n",
    "print(\"Ensure you have Streamlit installed. If not, install it with: pip install streamlit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

