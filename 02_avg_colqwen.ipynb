{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Search Optimization with Average Vector + Rescoring\n",
    "\n",
    "This notebook demonstrates the **Average Vector and Rescoring** techniques from Elastic's Search Labs blog post, '[Scaling late interaction models in Elasticsearch](https://www.elastic.co/search-labs/blog/scale-late-interaction-model-colpali)'.\n",
    "\n",
    "**Demo Scenario:**\n",
    "\n",
    "1.  **Problem Definition**: For large-scale search, we create a single average vector per document to leverage Elasticsearch's fast `knn` search.\n",
    "2.  **Identifying the Trade-off**: We observe a drop in search quality (ranking degradation) when using `knn` search alone, compared to the high-quality results from Part 1.\n",
    "3.  **Presenting the Solution**: We use Elasticsearch's `rescore` API to perform a precise, secondary scoring calculation on the initial `knn` results using `rank_vectors`.\n",
    "4.  **Verifying the Result**: We show that rescoring successfully restores the top-quality document to the #1 rank, proving the effectiveness of this two-stage architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Environment Setup and Library Installation\n",
    "\n",
    "**[EN]** Install the necessary libraries, same as in Part 1.<br>\n",
    "**[KR]** Part 1ê³¼ ë™ì¼í•˜ê²Œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"git+https://github.com/illuin-tech/colpali.git\"\n",
    "!pip install -q \"transformers>=4.41.0\" accelerate Pillow elasticsearch python-dotenv tqdm numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries and Set Environment Variables\n",
    "\n",
    "**[EN]** Use the same environment setup as in Part 1. Define a new index name and field names for this optimization demo.<br>\n",
    "**[KR]** Part 1ê³¼ ë™ì¼í•œ í™˜ê²½ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë²ˆ ìµœì í™” ë°ëª¨ë¥¼ ìœ„í•´ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ì´ë¦„ê³¼ í•„ë“œ ì´ë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "dotenv_path = 'elastic.env'\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "ES_URL = os.getenv(\"ES_URL\")\n",
    "ES_API_KEY = os.getenv(\"ES_API_KEY\")\n",
    "\n",
    "if not ES_URL or not ES_API_KEY:\n",
    "    raise ValueError(f\"Please create an '{dotenv_path}' file and set ES_URL and ES_API_KEY variables.\")\n",
    "\n",
    "INDEX_NAME = \"colqwen-rvlcdip-demo-part2\"\n",
    "VECTOR_FIELD_NAME = \"colqwen_vectors\"\n",
    "AVG_VECTOR_FIELD_NAME = \"colqwen_avg_vector\"\n",
    "SAMPLED_DATA_DIR = \"samples/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load ColQwen Model and Verify Data Path\n",
    "\n",
    "**[EN]** Load the same model as in Part 1 and verify the path to the RVL-CDIP dataset.<br>\n",
    "**[KR]** Part 1ê³¼ ë™ì¼í•œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , RVL-CDIP ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colpali_engine.models import ColQwen2_5, ColQwen2_5_Processor\n",
    "\n",
    "device_map = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device_map = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device_map = \"cuda:0\"\n",
    "print(f\"Using device: {device_map}\")\n",
    "\n",
    "MODEL_NAME = \"tsystems/colqwen2.5-3b-multilingual-v1.0\"\n",
    "model = ColQwen2_5.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16 if device_map != \"cpu\" else torch.float32,\n",
    "    device_map=device_map\n",
    ").eval()\n",
    "\n",
    "processor = ColQwen2_5_Processor.from_pretrained(MODEL_NAME)\n",
    "print(f\"Model '{MODEL_NAME}' loaded successfully.\")\n",
    "\n",
    "image_paths = []\n",
    "if os.path.exists(SAMPLED_DATA_DIR):\n",
    "    for category_dir in os.listdir(SAMPLED_DATA_DIR):\n",
    "        full_category_path = os.path.join(SAMPLED_DATA_DIR, category_dir)\n",
    "        if os.path.isdir(full_category_path):\n",
    "            image_paths.extend(glob.glob(os.path.join(full_category_path, '*.*')))\n",
    "print(f\"Found {len(image_paths)} sample images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Helper Functions for Embeddings\n",
    "\n",
    "**[EN]** In addition to the existing embedding functions, define a new function to calculate a single, normalized average vector from a set of multi-vectors.<br>\n",
    "**[KR]** ê¸°ì¡´ ì„ë² ë”© ìƒì„± í•¨ìˆ˜ì™€ ë”ë¶ˆì–´, ë‹¤ì¤‘ ë²¡í„°ë¥¼ ì…ë ¥ë°›ì•„ ì •ê·œí™”ëœ ë‹¨ì¼ í‰ê·  ë²¡í„°ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì¶”ê°€ë¡œ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colqwen_document_vectors(image_path):\n",
    "    \"\"\"Generates multi-vector embeddings for a document image.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor.process_images([image]).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        return outputs.cpu().to(torch.float32).numpy().tolist()[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_colqwen_query_vectors(query_text):\n",
    "    \"\"\"Generates multi-vector embeddings for a text query.\"\"\"\n",
    "    inputs = processor.process_queries([query_text]).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.cpu().to(torch.float32).numpy().tolist()[0]\n",
    "\n",
    "def calculate_average_vector(vectors):\n",
    "    \"\"\"Calculates a single, normalized average vector from multi-vectors.\"\"\"\n",
    "    if not vectors or len(vectors) == 0:\n",
    "        return None\n",
    "    avg_vec = np.array(vectors).mean(axis=0)\n",
    "    norm = np.linalg.norm(avg_vec)\n",
    "    if norm == 0:\n",
    "        return avg_vec.tolist()\n",
    "    return (avg_vec / norm).tolist()\n",
    "\n",
    "def to_bit_vectors(embeddings: list) -> list:\n",
    "    \"\"\"\n",
    "    Converts a list of float vectors into a list of hex-encoded bit vectors\n",
    "    for use with rank_vectors fields where element_type is 'bit'.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        np.packbits(np.where(np.array(embedding) > 0, 1, 0))\n",
    "        .astype(np.int8)\n",
    "        .tobytes()\n",
    "        .hex()\n",
    "        for embedding in embeddings\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Elasticsearch Index with Two Vector Fields\n",
    "\n",
    "**[EN]** This is the core of the demo. We create an index with both a `dense_vector` field for the average vector (for `knn` search) and a `rank_vectors` field for the original multi-vectors (for `rescoring`).<br>\n",
    "**[KR]** ì´ ë°ëª¨ì˜ í•µì‹¬ì…ë‹ˆë‹¤. í•˜ë‚˜ì˜ ì¸ë±ìŠ¤ì— `knn` ê²€ìƒ‰ì„ ìœ„í•œ `dense_vector` íƒ€ì…ì˜ í‰ê·  ë²¡í„° í•„ë“œì™€ `rescoring`ì„ ìœ„í•œ `rank_vectors` íƒ€ì…ì˜ ì›ë³¸ ë‹¤ì¤‘ ë²¡í„° í•„ë“œë¥¼ ëª¨ë‘ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically detect if ES_URL is a Cloud ID or a Host URL.\n",
    "if ':' in ES_URL and not ES_URL.startswith('http'):\n",
    "    # Connect using Cloud ID\n",
    "    print(\"Connecting using Cloud ID...\")\n",
    "    es = Elasticsearch(\n",
    "        cloud_id=ES_URL,\n",
    "        api_key=ES_API_KEY,\n",
    "        request_timeout=10\n",
    "    )\n",
    "else:\n",
    "    # Connect using Host URL\n",
    "    print(\"Connecting using Host URL...\")\n",
    "    es = Elasticsearch(\n",
    "        hosts=[ES_URL],\n",
    "        api_key=ES_API_KEY,\n",
    "        request_timeout=10,\n",
    "        verify_certs=False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "\n",
    "print(f\"Connected to Elasticsearch version: {es.info()['version']['number']}\")\n",
    "\n",
    "# Define the index mapping with all optimizations.\n",
    "# 1. dense_vector uses automatic BBQ via index_options.\n",
    "# 2. rank_vectors uses manual binary quantization via element_type: 'bit'.\n",
    "mapping = {\n",
    "    \"properties\": {\n",
    "        AVG_VECTOR_FIELD_NAME: {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 128,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"dot_product\",\n",
    "            \"index_options\": {\n",
    "                \"type\": \"bbq_hnsw\"\n",
    "            }\n",
    "        },\n",
    "        VECTOR_FIELD_NAME: {\n",
    "            \"type\": \"rank_vectors\",\n",
    "            \"dims\": 128,\n",
    "            \"element_type\": \"bit\"\n",
    "        },\n",
    "        \"image_path\": {\"type\": \"keyword\"},\n",
    "        \"category\": {\"type\": \"keyword\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check if the index already exists and is valid (has 1600 documents).\n",
    "# If not, recreate it to ensure data integrity.\n",
    "if es.indices.exists(index=INDEX_NAME):\n",
    "    try:\n",
    "        doc_count = es.count(index=INDEX_NAME)['count']\n",
    "        print(f\"Index '{INDEX_NAME}' already exists with {doc_count} documents.\")\n",
    "        if doc_count != 1600:\n",
    "            print(\"Document count is incorrect. Re-indexing...\")\n",
    "            es.indices.delete(index=INDEX_NAME)\n",
    "            es.indices.create(index=INDEX_NAME, mappings=mapping)\n",
    "        else:\n",
    "            print(\"Index is valid.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking index: {e}. Recreating index.\")\n",
    "        es.indices.delete(index=INDEX_NAME)\n",
    "        es.indices.create(index=INDEX_NAME, mappings=mapping)\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' not found. Creating new index.\")\n",
    "    es.indices.create(index=INDEX_NAME, mappings=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Index the Data (If Necessary)\n",
    "\n",
    "**[EN]** If the index was newly created or invalid, index all 1600 documents. This time, we generate and store both the average vector and the original multi-vectors for each document.<br>\n",
    "**[KR]** ì¸ë±ìŠ¤ê°€ ìƒˆë¡œ ìƒì„±ë˜ì—ˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°, 1600ê°œì˜ ë¬¸ì„œë¥¼ ëª¨ë‘ ì¸ë±ì‹±í•©ë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ê° ë¬¸ì„œì— ëŒ€í•´ í‰ê·  ë²¡í„°ì™€ ì›ë³¸ ë‹¤ì¤‘ ë²¡í„°ë¥¼ ëª¨ë‘ ìƒì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_count = es.count(index=INDEX_NAME)['count']\n",
    "if doc_count < 1600:\n",
    "    MAX_DOCS_TO_INDEX = 1600\n",
    "    docs_to_index = image_paths[:min(len(image_paths), MAX_DOCS_TO_INDEX)]\n",
    "    print(f\"Indexing {len(docs_to_index)} documents...\")\n",
    "\n",
    "    for path in tqdm(docs_to_index, desc=\"Indexing Documents\"):\n",
    "        doc_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        category = os.path.basename(os.path.dirname(path))\n",
    "        \n",
    "        # Generate both multi-vectors and the average vector\n",
    "        multi_vectors = create_colqwen_document_vectors(path)\n",
    "        if multi_vectors:\n",
    "            avg_vector = calculate_average_vector(multi_vectors)\n",
    "            bit_vectors = to_bit_vectors(multi_vectors)\n",
    "            \n",
    "            es_doc = {\n",
    "                VECTOR_FIELD_NAME: bit_vectors,\n",
    "                AVG_VECTOR_FIELD_NAME: avg_vector,\n",
    "                \"image_path\": path,\n",
    "                \"category\": category\n",
    "            }\n",
    "            es.index(index=INDEX_NAME, id=doc_id, document=es_doc)\n",
    "\n",
    "    es.indices.refresh(index=INDEX_NAME)\n",
    "    print(\"\\nIndexing complete.\")\n",
    "else:\n",
    "    print(\"All documents are already indexed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Demonstrate the Problem: KNN Search Only\n",
    "\n",
    "**[EN]** First, let's perform a search using only the fast `knn` query. Pay attention to how the rank of the document that was #1 in Part 1 changes. This demonstrates the trade-off: we gain speed but lose some precision.<br>\n",
    "**[KR]** ë¨¼ì € ë¹ ë¥¸ `knn` ê²€ìƒ‰ë§Œ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. Part 1ì—ì„œ 1ìœ„ë¥¼ ì°¨ì§€í–ˆë˜ ë¬¸ì„œì˜ ìˆœìœ„ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì£¼ëª©í•©ë‹ˆë‹¤. ì´ëŠ” ì†ë„ë¥¼ ì–»ëŠ” ëŒ€ì‹  ì •ë°€ë„ë¥¼ ì¼ë¶€ ìƒëŠ” íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "def remove_query_vector_from_explanation(explanation_obj):\n",
    "    \"\"\"\n",
    "    Recursively traverses the explanation object to remove the lengthy 'query_vector' parameter\n",
    "    from both structured 'params' and string-based 'description' fields.\n",
    "    \"\"\"\n",
    "    if isinstance(explanation_obj, dict):\n",
    "        if 'description' in explanation_obj and isinstance(explanation_obj['description'], str):\n",
    "            explanation_obj['description'] = re.sub(\n",
    "                r\"query_vector=\\[\\[.*?\\]\\]\", \n",
    "                \"query_vector=[...vector omitted for brevity...]\", \n",
    "                explanation_obj['description']\n",
    "            )\n",
    "        if 'params' in explanation_obj and 'query_vector' in explanation_obj['params']:\n",
    "            explanation_obj['params']['query_vector'] = \"[...vector omitted for brevity...]\"\n",
    "        for key, value in explanation_obj.items():\n",
    "            remove_query_vector_from_explanation(value)\n",
    "    elif isinstance(explanation_obj, list):\n",
    "        for item in explanation_obj:\n",
    "            remove_query_vector_from_explanation(item)\n",
    "    return explanation_obj\n",
    "\n",
    "# Add a more robust query that is likely to be recovered by rescore\n",
    "queries_to_test = [\n",
    "    \"Please find the order form I received by fax in July.\",\n",
    "    \"ì§€ë‚œ 7ì›”ì— fax ë¡œ ë°›ì€ ë°œì£¼ì„œ ì°¾ì•„ì¤˜\"\n",
    "]\n",
    "\n",
    "def display_results(hits):\n",
    "    html = \"<table><tr>\"\n",
    "    for i, hit in enumerate(hits):\n",
    "        doc_id = hit[\"_id\"]\n",
    "        score = hit[\"_score\"]\n",
    "        path = hit[\"_source\"][\"image_path\"]\n",
    "        category = hit[\"_source\"][\"category\"]\n",
    "        try:\n",
    "            with open(path, \"rb\") as image_file:\n",
    "                img_str = base64.b64encode(image_file.read()).decode()\n",
    "                html += f\"<td style='text-align: center; vertical-align: top; padding: 10px; border: 1px solid #ddd;'>\"\n",
    "                html += f\"<b>Rank #{i+1}</b><br><img src='data:image/png;base64,{img_str}' width='200'><br>\"\n",
    "                html += f\"<b>ID:</b> {doc_id[:15]}...<br><b>Score:</b> {score:.4f}<br><b>Category:</b> {category}</td>\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying image {path}: {e}\")\n",
    "    html += \"</tr></table>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "for query in queries_to_test:\n",
    "    print(f\"\\n{'='*20}\\n--- Scenario: B. KNN Search Only ---\")\n",
    "    print(f\"Searching for: '{query}'\\n{'='*20}\")\n",
    "\n",
    "    query_avg_vector = calculate_average_vector(create_colqwen_query_vectors(query))\n",
    "    \n",
    "    knn_query = {\n",
    "        \"field\": AVG_VECTOR_FIELD_NAME,\n",
    "        \"query_vector\": query_avg_vector,\n",
    "        \"k\": 200,\n",
    "        \"num_candidates\": 500\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = es.search(index=INDEX_NAME, knn=knn_query, size=5, source=[\"image_path\", \"category\"], explain=True)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    latency_ms = (end_time - start_time) * 1000\n",
    "    print(f\"ğŸš€ Search Latency: {latency_ms:.2f} ms\")\n",
    "\n",
    "    hits = results['hits']['hits']\n",
    "    \n",
    "    if hits:\n",
    "        display_results(hits)\n",
    "        \n",
    "        top_hit_explanation = hits[0].get(\"_explanation\")\n",
    "        if top_hit_explanation:\n",
    "            print(\"\\n--- Explanation for Top Result (Rank #1) ---\")\n",
    "            cleaned_explanation = remove_query_vector_from_explanation(top_hit_explanation)\n",
    "            print(json.dumps(cleaned_explanation, indent=2))\n",
    "    else:\n",
    "        print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Present the Solution: KNN + Rescoring\n",
    "\n",
    "**[EN]** Now, we solve this problem using the `rescore` API. For the top 10 documents found by the initial `knn` search, we recalculate a more precise score using `rank_vectors` to determine the final ranking. Observe how the original top-ranked document is restored.<br>\n",
    "**[KR]** ì´ì œ `rescore` APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. 1ì°¨ `knn` ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ìƒìœ„ 10ê°œ ë¬¸ì„œì— ëŒ€í•´ì„œë§Œ, `rank_vectors`ë¥¼ ì‚¬ìš©í•œ ì •ë°€í•œ ì ìˆ˜ ê³„ì‚°ì„ ë‹¤ì‹œ ìˆ˜í–‰í•˜ì—¬ ìµœì¢… ìˆœìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì›ë˜ 1ìœ„ì˜€ë˜ ë¬¸ì„œì˜ ìˆœìœ„ê°€ ì–´ë–»ê²Œ ë³µì›ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: KNN + Rescore (with Latency and Improved Parameters) ---\n",
    "\n",
    "for query in queries_to_test:\n",
    "    print(f\"\\n{'='*20}\\n--- Scenario: C. KNN with Rescoring ---\")\n",
    "    print(f\"Searching for: '{query}'\\n{'='*20}\")\n",
    "\n",
    "    query_multi_vectors = create_colqwen_query_vectors(query)\n",
    "    query_avg_vector = calculate_average_vector(query_multi_vectors)\n",
    "    \n",
    "    # Increase k and num_candidates to improve the chance of finding the true top result\n",
    "    knn_query = {\n",
    "        \"field\": AVG_VECTOR_FIELD_NAME,\n",
    "        \"query_vector\": query_avg_vector,\n",
    "        \"k\": 200,  # Widen the net\n",
    "        \"num_candidates\": 500 # Explore more candidates\n",
    "    }\n",
    "    \n",
    "    rescore_definition = {\n",
    "        \"window_size\": 50, # Rescore all candidates found by knn\n",
    "        \"query\": {\n",
    "            \"rescore_query\": {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\"match_all\": {}},\n",
    "                    \"script\": {\n",
    "                        \"source\": f\"maxSimDotProduct(params.query_vector, '{VECTOR_FIELD_NAME}')\",\n",
    "                        \"params\": {\"query_vector\": query_multi_vectors}\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"query_weight\": 0.0,\n",
    "            \"rescore_query_weight\": 1.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = es.search(\n",
    "        index=INDEX_NAME, \n",
    "        knn=knn_query, \n",
    "        rescore=rescore_definition, \n",
    "        size=5, \n",
    "        source=[\"image_path\", \"category\"],\n",
    "        explain=True\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    latency_ms = (end_time - start_time) * 1000\n",
    "    print(f\"ğŸš€ Search Latency: {latency_ms:.2f} ms\")\n",
    "\n",
    "    hits = results['hits']['hits']\n",
    "\n",
    "    if hits:\n",
    "        display_results(hits)\n",
    "        \n",
    "        top_hit_explanation = hits[0].get(\"_explanation\")\n",
    "        if top_hit_explanation:\n",
    "            print(\"\\n--- Explanation for Top Result (Rank #1) ---\")\n",
    "            cleaned_explanation = remove_query_vector_from_explanation(top_hit_explanation)\n",
    "            print(json.dumps(cleaned_explanation, indent=2))\n",
    "    else:\n",
    "        print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Free up GPU/MPS Memory\n",
    "\n",
    "**[EN]** As a best practice, explicitly delete the model and processor to free up GPU or system memory after the demonstration is complete.<br>\n",
    "**[KR]** ëª¨ë²” ì‚¬ë¡€ë¡œì„œ, ë°ëª¨ê°€ ì™„ë£Œëœ í›„ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚­ì œí•˜ì—¬ GPU ë˜ëŠ” ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del processor\n",
    "\n",
    "import gc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"CUDA cache cleared.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    print(\"MPS cache cleared.\")\n",
    "\n",
    "gc.collect()\n",
    "print(\"Memory cleanup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
