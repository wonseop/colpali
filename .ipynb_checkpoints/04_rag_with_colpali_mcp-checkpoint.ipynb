{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Interactive Guide for Agentic RAG with MCP (Local Setup)\n",
    "\n",
    "**[EN]** This notebook is an interactive guide for demonstrating an Agentic RAG workflow on your local machine. It will guide you through setting up the Elastic MCP Server and using an external AI agent (like Claude Desktop) to perform advanced searches on Elasticsearch.<br>\n",
    "**[KR]** 이 노트북은 당신의 로컬 컴퓨터에서 Agentic RAG 워크플로우를 시연하기 위한 대화형 가이드입니다. Elastic MCP 서버를 설정하고 Claude Desktop과 같은 외부 AI 에이전트를 사용하여 Elasticsearch에 대한 고급 검색을 수행하는 과정을 안내합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prerequisites\n",
    "\n",
    "**[EN]** Before you begin, please ensure you have the following installed on your local machine:<br>\n",
    "**[KR]** 시작하기 전에, 당신의 로컬 컴퓨터에 다음 프로그램들이 설치되어 있는지 확인해주세요:\n",
    "\n",
    "1.  **Python**: This project is based on Python. Ensure you have a working Python environment and have installed the dependencies from `requirements.txt`.\n",
    "2.  **Node.js**: The MCP Server is a Node.js application. Please install the latest LTS version from [nodejs.org](https://nodejs.org/).\n",
    "3.  **Claude Desktop**: This demo uses Claude Desktop as the AI agent. Make sure it is installed on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Server Execution and Connection (Manual Guide)\n",
    "\n",
    "**[EN]** The following steps require manual execution in your local terminal.<br>\n",
    "**[KR]** 다음 단계들은 당신의 로컬 터미널에서 직접 실행해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Create `package.json` and Install MCP Server\n",
    "\n",
    "**[EN]** This cell creates a `package.json` file. After running it, you will need to run `npm install` in your terminal.<br>\n",
    "**[KR]** 이 셀은 `package.json` 파일을 생성합니다. 셀을 실행한 후, 터미널에서 `npm install`을 실행해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "package_json = {\n",
    "    \"name\": \"colpali-mcp-demo\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"description\": \"A demo project to connect Claude Desktop with Elasticsearch via MCP.\",\n",
    "    \"dependencies\": {\n",
    "        \"@elastic/mcp-server-elasticsearch\": \"latest\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('package.json', 'w') as f:\n",
    "    json.dump(package_json, f, indent=2)\n",
    "\n",
    "print(\"package.json created successfully.\")\n",
    "print(\"\\nNext, open your terminal in this project directory and run: npm install\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Run the MCP Server in Your Local Terminal\n",
    "\n",
    "1. **Open a new terminal** (e.g., Command Prompt, PowerShell, Terminal.app) in this project's root directory.\n",
    "2. **Copy and paste the commands below** for your operating system. It will load your Elasticsearch credentials and start the server.\n",
    "\n",
    "**For macOS/Linux:**\n",
    "```bash\n",
    "# (You can copy the credentials from the output of the next cell)\n",
    "export ES_URL=\"<your-elasticsearch-url>\"\n",
    "export ES_API_KEY=\"<your-api-key>\"\n",
    "npx @elastic/mcp-server-elasticsearch\n",
    "```\n",
    "**For Windows (Command Prompt):**\n",
    "```cmd\n",
    "set ES_URL=\"<your-elasticsearch-url>\"\n",
    "set ES_API_KEY=\"<your-api-key>\"\n",
    "npx @elastic/mcp-server-elasticsearch\n",
    "```\n",
    "**Important**: Keep this terminal running. The server must be active for the AI agent to connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = 'elastic.env'\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "ES_URL = os.getenv(\"ES_URL\", \"\")\n",
    "ES_API_KEY = os.getenv(\"ES_API_KEY\", \"\")\n",
    "\n",
    "print(\"--- Copy these values for the terminal command above ---\")\n",
    "print(f\"Your ES_URL is: {ES_URL}\")\n",
    "print(f\"Your ES_API_KEY is: {ES_API_KEY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3: Configure Claude Desktop\n",
    "\n",
    "1. Open the **Claude Desktop App**.\n",
    "2. Navigate to `Settings > Developer > MCP Servers` and click **'Edit Config'**.\n",
    "3. Add the following JSON configuration. Since the server is running on your local machine, you can connect to it directly via `localhost`.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"elasticsearch-mcp-server\": {\n",
    "            \"url\": \"http://localhost:8889/mcp/v1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "4. Save the file. Claude should now be connected to your local MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Agentic RAG Demonstration (Interactive)\n",
    "\n",
    "**[EN]** Now, we will simulate a customer's request. This cell will generate a complete, advanced Elasticsearch query based on your input. You will then copy this query and run it in Claude Desktop to demonstrate the Agentic RAG workflow.<br>\n",
    "**[KR]** 이제 고객의 요청을 시뮬레이션합니다. 이 셀은 사용자의 입력에 따라 완전하고 진보된 Elasticsearch 쿼리를 생성합니다. 이 쿼리를 복사하여 Claude Desktop에서 실행함으로써 Agentic RAG 워크플로우를 시연합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "from colpali_engine.models import ColQwen2_5, ColQwen2_5_Processor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# --- Helper functions (already defined in other notebooks, included here for completeness) ---\n",
    "device_map = \"cpu\"\n",
    "if torch.backends.mps.is_available(): device_map = \"mps\"\n",
    "elif torch.cuda.is_available(): device_map = \"cuda:0\"\n",
    "MODEL_NAME = \"tsystems/colqwen2.5-3b-multilingual-v1.0\"\n",
    "model = ColQwen2_5.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16 if device_map != \"cpu\" else torch.float32, device_map=device_map).eval()\n",
    "processor = ColQwen2_5_Processor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def create_colqwen_query_vectors(query_text, model, processor):\n",
    "    inputs = processor.process_queries([query_text]).to(model.device)\n",
    "    with torch.no_grad(): outputs = model(**inputs)\n",
    "    return outputs.cpu().to(torch.float32).numpy().tolist()[0]\n",
    "\n",
    "def to_avg_vector(vectors):\n",
    "    vectors_array = np.array(vectors)\n",
    "    avg_vector = np.mean(vectors_array, axis=0)\n",
    "    norm = np.linalg.norm(avg_vector)\n",
    "    return (avg_vector / norm).tolist() if norm > 0 else avg_vector.tolist()\n",
    "\n",
    "# --- Interactive UI --- \n",
    "query_input = widgets.Text(value='Do you have a benefits policy change notice from HR?', description='Query:', layout=widgets.Layout(width='95%'))\n",
    "mode_selector = widgets.RadioButtons(options=['A. Full Colpali Search', 'B. KNN Search Only', 'C. KNN + Rescore'], description='Search Mode:')\n",
    "generate_button = widgets.Button(description=\"Generate Agent Command\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def generate_agent_command(b):\n",
    "    output_area.clear_output()\n",
    "    query_text = query_input.value\n",
    "    search_mode = mode_selector.value\n",
    "    \n",
    "    with output_area:\n",
    "        print(\"Generating vectors and Elasticsearch query...\")\n",
    "        query_multi_vectors = create_colqwen_query_vectors(query_text, model, processor)\n",
    "        es_query_body = {}\n",
    "        index_name = \"\"\n",
    "\n",
    "        if search_mode.startswith('A.'):\n",
    "            index_name = \"colqwen-rvlcdip-demo-part1\"\n",
    "            es_query_body = {\"size\": 5, \"query\": {\"script_score\": {\"query\": {\"match_all\": {}}, \"script\": {\"source\": \"maxSimDotProduct(params.query_vector, 'colqwen_vectors')\", \"params\": {\"query_vector\": query_multi_vectors}}}}}\n",
    "        else:\n",
    "            index_name = \"colqwen-rvlcdip-demo-part2\"\n",
    "            query_avg_vector = to_avg_vector(query_multi_vectors)\n",
    "            knn_query = {\"field\": \"colqwen_avg_vector\", \"query_vector\": query_avg_vector, \"k\": 200, \"num_candidates\": 500}\n",
    "            if search_mode.startswith('B.'):\n",
    "                es_query_body = {\"size\": 5, \"knn\": knn_query}\n",
    "            else: # C. KNN + Rescore\n",
    "                rescore_def = {\"window_size\": 50, \"query\": {\"rescore_query\": {\"script_score\": {\"query\": {\"match_all\": {}}, \"script\": {\"source\": \"maxSimDotProduct(params.query_vector, 'colqwen_vectors')\", \"params\": {\"query_vector\": query_multi_vectors}}}}, \"query_weight\": 0.0, \"rescore_query_weight\": 1.0}}\n",
    "                es_query_body = {\"size\": 5, \"knn\": knn_query, \"rescore\": rescore_def}\n",
    "        \n",
    "        # Pretty print the JSON query\n",
    "        query_json_string = json.dumps(es_query_body, indent=2)\n",
    "        \n",
    "        # Generate the final prompt for the AI Agent\n",
    "        agent_prompt = f\"\"\"@elasticsearch-mcp-server search index {index_name} with query: {query_json_string}\"\"\"\n",
    "        \n",
    "        print(\"Done!\\n\")\n",
    "        display(Markdown(\"**Copy the following command and paste it into Claude Desktop:**\"))\n",
    "        display(Markdown(f\"```\\n{agent_prompt}\\n```\"))\n",
    "\n",
    "generate_button.on_click(generate_agent_command)\n",
    "display(widgets.VBox([query_input, mode_selector, generate_button, output_area]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
