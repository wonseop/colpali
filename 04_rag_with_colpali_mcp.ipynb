{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Interactive Guide for Agentic RAG with MCP (Local Setup)\n",
    "\n",
    "**[EN]** This notebook is an interactive guide for demonstrating an Agentic RAG workflow on your local machine. It will guide you through setting up the Elastic MCP Server and using an external AI agent (like Claude Desktop) to perform advanced searches on Elasticsearch.<br>\n",
    "**[KR]** 이 노트북은 당신의 로컬 컴퓨터에서 Agentic RAG 워크플로우를 시연하기 위한 대화형 가이드입니다. Elastic MCP 서버를 설정하고 Claude Desktop과 같은 외부 AI 에이전트를 사용하여 Elasticsearch에 대한 고급 검색을 수행하는 과정을 안내합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prerequisites\n",
    "\n",
    "**[EN]** Before you begin, please ensure you have the following installed on your local machine:<br>\n",
    "**[KR]** 시작하기 전에, 당신의 로컬 컴퓨터에 다음 프로그램들이 설치되어 있는지 확인해주세요:\n",
    "\n",
    "1.  **Python**: This project is based on Python. Ensure you have a working Python environment and have installed the dependencies from `requirements.txt`.\n",
    "2.  **Docker**: The new MCP Server is a Docker image. Please install Docker from [docker.com](https://www.docker.com/products/docker-desktop/).\n",
    "3.  **Claude Desktop**: This demo uses Claude Desktop as the AI agent. Make sure it is installed on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Server Execution and Connection (Manual Guide)\n",
    "\n",
    "**[EN]** The following steps require manual execution in your local terminal.<br>\n",
    "**[KR]** 다음 단계들은 당신의 로컬 터미널에서 직접 실행해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Run the MCP Server using Docker\n",
    "\n",
    "1. **Open a new terminal** in your project's root directory.\n",
    "2. **Run the Docker command below.** This command will download the latest MCP server image and run it as a container. It directly passes your Elasticsearch credentials as environment variables to the container.\n",
    "\n",
    "```bash\n",
    "docker run -i --rm \\\n",
    "  -e ES_URL=\"<your-elasticsearch-url>\" \\\n",
    "  -e ES_API_KEY=\"<your-api-key>\" \\\n",
    "  -p 8889:8889 \\\n",
    "  docker.elastic.co/mcp/elasticsearch http\n",
    "```\n",
    "*(Note: Copy the values from your `elastic.env` file to fill in the `<...>` placeholders.)*\n",
    "\n",
    "**Important**: Keep this terminal running. The server must be active for the AI agent to connect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Configure Claude Desktop\n",
    "\n",
    "1. Open the **Claude Desktop App**.\n",
    "2. Navigate to `Settings > Developer > MCP Servers` and click **'Edit Config'**.\n",
    "3. Add the following JSON configuration. This connects to the server running via Docker.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"elasticsearch-mcp-server\": {\n",
    "            \"url\": \"http://localhost:8889/mcp/v1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "4. Save the file. Claude should now be connected to your MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Agentic RAG Demonstration (Interactive)\n",
    "\n",
    "**[EN]** Now, we will simulate a customer's request. This cell will generate a complete, advanced Elasticsearch query based on your input. You will then copy this query and run it in Claude Desktop to demonstrate the Agentic RAG workflow.<br>\n",
    "**[KR]** 이제 고객의 요청을 시뮬레이션합니다. 이 셀은 사용자의 입력에 따라 완전하고 진보된 Elasticsearch 쿼리를 생성합니다. 이 쿼리를 복사하여 Claude Desktop에서 실행함으로써 Agentic RAG 워크플로우를 시연합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "from colpali_engine.models import ColQwen2_5, ColQwen2_5_Processor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# --- Helper functions (already defined in other notebooks, included here for completeness) ---\n",
    "device_map = \"cpu\"\n",
    "if torch.backends.mps.is_available(): device_map = \"mps\"\n",
    "elif torch.cuda.is_available(): device_map = \"cuda:0\"\n",
    "MODEL_NAME = \"tsystems/colqwen2.5-3b-multilingual-v1.0\"\n",
    "model = ColQwen2_5.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16 if device_map != \"cpu\" else torch.float32, device_map=device_map).eval()\n",
    "processor = ColQwen2_5_Processor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def create_colqwen_query_vectors(query_text, model, processor):\n",
    "    inputs = processor.process_queries([query_text]).to(model.device)\n",
    "    with torch.no_grad(): outputs = model(**inputs)\n",
    "    return outputs.cpu().to(torch.float32).numpy().tolist()[0]\n",
    "\n",
    "def to_avg_vector(vectors):\n",
    "    vectors_array = np.array(vectors)\n",
    "    avg_vector = np.mean(vectors_array, axis=0)\n",
    "    norm = np.linalg.norm(avg_vector)\n",
    "    return (avg_vector / norm).tolist() if norm > 0 else avg_vector.tolist()\n",
    "\n",
    "# --- Interactive UI --- \n",
    "query_input = widgets.Text(value='Do you have a benefits policy change notice from HR?', description='Query:', layout=widgets.Layout(width='95%'))\n",
    "mode_selector = widgets.RadioButtons(options=['A. Full Colpali Search', 'B. KNN Search Only', 'C. KNN + Rescore'], description='Search Mode:')\n",
    "generate_button = widgets.Button(description=\"Generate Agent Command\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def generate_agent_command(b):\n",
    "    output_area.clear_output()\n",
    "    query_text = query_input.value\n",
    "    search_mode = mode_selector.value\n",
    "    \n",
    "    with output_area:\n",
    "        print(\"Generating vectors and Elasticsearch query...\")\n",
    "        query_multi_vectors = create_colqwen_query_vectors(query_text, model, processor)\n",
    "        es_query_body = {}\n",
    "        index_name = \"\"\n",
    "\n",
    "        if search_mode.startswith('A.'):\n",
    "            index_name = \"colqwen-rvlcdip-demo-part1\"\n",
    "            es_query_body = {\"size\": 5, \"query\": {\"script_score\": {\"query\": {\"match_all\": {}}, \"script\": {\"source\": \"maxSimDotProduct(params.query_vector, 'colqwen_vectors')\", \"params\": {\"query_vector\": query_multi_vectors}}}}}\n",
    "        else:\n",
    "            index_name = \"colqwen-rvlcdip-demo-part2\"\n",
    "            query_avg_vector = to_avg_vector(query_multi_vectors)\n",
    "            knn_query = {\"field\": \"colqwen_avg_vector\", \"query_vector\": query_avg_vector, \"k\": 200, \"num_candidates\": 500}\n",
    "            if search_mode.startswith('B.'):\n",
    "                es_query_body = {\"size\": 5, \"knn\": knn_query}\n",
    "            else: # C. KNN + Rescore\n",
    "                rescore_def = {\"window_size\": 50, \"query\": {\"rescore_query\": {\"script_score\": {\"query\": {\"match_all\": {}}, \"script\": {\"source\": \"maxSimDotProduct(params.query_vector, 'colqwen_vectors')\", \"params\": {\"query_vector\": query_multi_vectors}}}}, \"query_weight\": 0.0, \"rescore_query_weight\": 1.0}}\n",
    "                es_query_body = {\"size\": 5, \"knn\": knn_query, \"rescore\": rescore_def}\n",
    "        \n",
    "        # Pretty print the JSON query\n",
    "        query_json_string = json.dumps(es_query_body, indent=2)\n",
    "        \n",
    "        # Generate the final prompt for the AI Agent\n",
    "        agent_prompt = f\"\"\"@elasticsearch-mcp-server search index {index_name} with query: {query_json_string}\"\"\"\n",
    "        \n",
    "        print(\"Done!\\n\")\n",
    "        display(Markdown(\"**Copy the following command and paste it into Claude Desktop:**\"))\n",
    "        display(Markdown(f\"```\\n{agent_prompt}\\n```\"))\n",
    "\n",
    "generate_button.on_click(generate_agent_command)\n",
    "display(widgets.VBox([query_input, mode_selector, generate_button, output_area]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
