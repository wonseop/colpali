{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Interactive Guide for Agentic RAG with MCP (Local Setup)\n",
    "\n",
    "**[EN]** This notebook is an interactive guide for demonstrating an Agentic RAG workflow on your local machine. It will guide you through setting up the Elastic MCP Server and using an external AI agent (like Claude Desktop) to perform advanced searches on Elasticsearch.<br>\n",
    "**[KR]** ì´ ë…¸íŠ¸ë¶ì€ ë‹¹ì‹ ì˜ ë¡œì»¬ ì»´í“¨í„°ì—ì„œ Agentic RAG ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì—°í•˜ê¸° ìœ„í•œ ëŒ€í™”í˜• ê°€ì´ë“œì…ë‹ˆë‹¤. Elastic MCP ì„œë²„ë¥¼ ì„¤ì •í•˜ê³  Claude Desktopê³¼ ê°™ì€ ì™¸ë¶€ AI ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ Elasticsearchì— ëŒ€í•œ ê³ ê¸‰ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prerequisites\n",
    "\n",
    "**[EN]** Before you begin, please ensure you have the following installed on your local machine:<br>\n",
    "**[KR]** ì‹œì‘í•˜ê¸° ì „ì—, ë‹¹ì‹ ì˜ ë¡œì»¬ ì»´í“¨í„°ì— ë‹¤ìŒ í”„ë¡œê·¸ë¨ë“¤ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "1.  **Python**: This project is based on Python. Ensure you have a working Python environment and have installed the dependencies from `requirements.txt`.\n",
    "2.  **Docker**: The new MCP Server is a Docker image. Please install Docker from [docker.com](https://www.docker.com/products/docker-desktop/).\n",
    "3.  **Claude Desktop**: This demo uses Claude Desktop as the AI agent. Make sure it is installed on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Server Execution and Connection (Manual Guide)\n",
    "\n",
    "**[EN]** The following steps require manual execution in your local terminal.<br>\n",
    "**[KR]** ë‹¤ìŒ ë‹¨ê³„ë“¤ì€ ë‹¹ì‹ ì˜ ë¡œì»¬ í„°ë¯¸ë„ì—ì„œ ì§ì ‘ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Generate Docker Command and Run MCP Server\n",
    "\n",
    "**[EN]** This Python cell reads your `elastic.env` file and generates the exact `docker run` command for you. Run this cell, then copy the output command and run it in your terminal.\n",
    "\n",
    "**[KR]** ì´ Python ì…€ì€ `elastic.env` íŒŒì¼ì„ ì½ì–´ ì™„ì „í•œ `docker run` ëª…ë ¹ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ì…€ì„ ì‹¤í–‰í•œ í›„, ì¶œë ¥ë˜ëŠ” ëª…ë ¹ì–´ë¥¼ ë³µì‚¬í•˜ì—¬ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load credentials from elastic.env\n",
    "dotenv_path = 'elastic.env'\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "es_url = os.getenv(\"ES_URL\", \"\")\n",
    "es_api_key = os.getenv(\"ES_API_KEY\", \"\")\n",
    "\n",
    "if not es_url or not es_api_key:\n",
    "    print(\"âš ï¸ Error: Please make sure 'elastic.env' file exists and contains ES_URL and ES_API_KEY.\")\n",
    "else:\n",
    "    # Generate the complete docker command\n",
    "    docker_command = (\n",
    "        f'docker run -i --rm \\\\\\n'\n",
    "        f'  -e ES_URL=\"{es_url}\" \\\\\\n'\n",
    "        f'  -e ES_API_KEY=\"{es_api_key}\" \\\\\\n'\n",
    "        f'  -p 8889:8889 \\\\\\n'\n",
    "        f'  docker.elastic.co/mcp/elasticsearch http'\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Docker command generated successfully.\")\n",
    "    print(\"ğŸ‘‡ Copy the command below and run it in your terminal:\\n\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(docker_command)\n",
    "    print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Configure Claude Desktop\n",
    "\n",
    "1. Open the **Claude Desktop App**.\n",
    "2. Navigate to `Settings > Developer > MCP Servers` and click **'Edit Config'**.\n",
    "3. Add the following JSON configuration. This connects to the server running via Docker.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"elasticsearch-mcp-server\": {\n",
    "            \"url\": \"http://localhost:8889/mcp/v1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "4. Save the file. Claude should now be connected to your MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Agentic RAG Demonstration (Interactive)\n",
    "\n",
    "**[EN]** Now, we will simulate a customer's request. This cell will generate a complete, advanced Elasticsearch query based on your input. You will then copy this query and run it in Claude Desktop to demonstrate the Agentic RAG workflow.<br>\n",
    "**[KR]** ì´ì œ ê³ ê°ì˜ ìš”ì²­ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤. ì´ ì…€ì€ ì‚¬ìš©ìì˜ ì…ë ¥ì— ë”°ë¼ ì™„ì „í•˜ê³  ì§„ë³´ëœ Elasticsearch ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ì¿¼ë¦¬ë¥¼ ë³µì‚¬í•˜ì—¬ Claude Desktopì—ì„œ ì‹¤í–‰í•¨ìœ¼ë¡œì¨ Agentic RAG ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì—°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "from colpali_engine.models import ColQwen2_5, ColQwen2_5_Processor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# --- Helper functions (already defined in other notebooks, included here for completeness) ---\n",
    "device_map = \"cpu\"\n",
    "if torch.backends.mps.is_available(): device_map = \"mps\"\n",
    "elif torch.cuda.is_available(): device_map = \"cuda:0\"\n",
    "MODEL_NAME = \"tsystems/colqwen2.5-3b-multilingual-v1.0\"\n",
    "model = ColQwen2_5.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16 if device_map != \"cpu\" else torch.float32, device_map=device_map).eval()\n",
    "processor = ColQwen2_5_Processor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def create_colqwen_query_vectors(query_text, model, processor):\n",
    "    inputs = processor.process_queries([query_text]).to(model.device)\n",
    "    with torch.no_grad(): outputs = model(**inputs)\n",
    "    return outputs.cpu().to(torch.float32).numpy().tolist()[0]\n",
    "\n",
    "def to_avg_vector(vectors):\n",
    "    vectors_array = np.array(vectors)\n",
    "    avg_vector = np.mean(vectors_array, axis=0)\n",
    "    norm = np.linalg.norm(avg_vector)\n",
    "    return (avg_vector / norm).tolist() if norm > 0 else avg_vector.tolist()\n",
    "\n",
    "# --- Interactive UI --- \n",
    "query_input = widgets.Text(value='Do you have a benefits policy change notice from HR?', description='Query:', layout=widgets.Layout(width='95%'))\n",
    "mode_selector = widgets.RadioButtons(options=['A. Full Colpali Search', 'B. KNN Search Only', 'C. KNN + Rescore'], description='Search Mode:')\n",
    "generate_button = widgets.Button(description=\"Generate Agent Command\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def generate_agent_command(b):\n",
    "    output_area.clear_output()\n",
    "    query_text = query_input.value\n",
    "    search_mode = mode_selector.value\n",
    "    \n",
    "    with output_area:\n",
    "        print(\"Generating vectors and Elasticsearch query...\")\n",
    "        query_multi_vectors = create_colqwen_query_vectors(query_text, model, processor)\n",
    "        es_query_body = {}\n",
    "        index_name = \"\"\n",
    "\n",
    "        if search_mode.startswith('A.'):\n",
    "            index_name = \"colqwen-rvlcdip-demo-part1\"\n",
    "            es_query_body = {\"size\": 5, \"query\": {\"script_score\": {\"query\": {\"match_all\": {}}, \"script\": {\"source\": \"maxSimDotProduct(params.query_vector, 'colqwen_vectors')\", \"params\": {\"query_vector\": query_multi_vectors}}}}}\n",
    "        else:\n",
    "            index_name = \"colqwen-rvlcdip-demo-part2\"\n",
    "            query_avg_vector = to_avg_vector(query_multi_vectors)\n",
    "            knn_query = {\"field\": \"colqwen_avg_vector\", \"query_vector\": query_avg_vector, \"k\": 200, \"num_candidates\": 500}\n",
    "            if search_mode.startswith('B.'):\n",
    "                es_query_body = {\"size\": 5, \"knn\": knn_query}\n",
    "            else: # C. KNN + Rescore\n",
    "                rescore_def = {\"window_size\": 50, \"query\": {\"rescore_query\": {\"script_score\": {\"query\": {\"match_all\": {}}, \"script\": {\"source\": \"maxSimDotProduct(params.query_vector, 'colqwen_vectors')\", \"params\": {\"query_vector\": query_multi_vectors}}}}, \"query_weight\": 0.0, \"rescore_query_weight\": 1.0}}\n",
    "                es_query_body = {\"size\": 5, \"knn\": knn_query, \"rescore\": rescore_def}\n",
    "        \n",
    "        # Pretty print the JSON query\n",
    "        query_json_string = json.dumps(es_query_body, indent=2)\n",
    "        \n",
    "        # Generate the final prompt for the AI Agent\n",
    "        agent_prompt = f\"\"\"@elasticsearch-mcp-server search index {index_name} with query: {query_json_string}\"\"\"\n",
    "        \n",
    "        print(\"Done!\\n\")\n",
    "        display(Markdown(\"**Copy the following command and paste it into Claude Desktop:**\"))\n",
    "        display(Markdown(f\"```\\n{agent_prompt}\\n```\"))\n",
    "\n",
    "generate_button.on_click(generate_agent_command)\n",
    "display(widgets.VBox([query_input, mode_selector, generate_button, output_area]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
